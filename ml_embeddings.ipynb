{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ml_embeddings.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/acesaif/ml_crash_course/blob/master/ml_embeddings.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "q9jUc9NwH4HT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ]
    },
    {
      "metadata": {
        "id": "AMzwoDSDH6Qs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import collections\n",
        "import math\n",
        "\n",
        "from IPython import display\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn import metrics\n",
        "\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UzRL8JNZImN1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Load Dataset"
      ]
    },
    {
      "metadata": {
        "id": "mGsmgvKbJN0g",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_url = 'https://storage.googleapis.com/mledu-datasets/sparse-data-embedding/train.tfrecord'\n",
        "train_path = tf.keras.utils.get_file(train_url.split('/')[-1], train_url)\n",
        "test_url = 'https://storage.googleapis.com/mledu-datasets/sparse-data-embedding/test.tfrecord'\n",
        "test_path = tf.keras.utils.get_file(test_url.split('/')[-1], test_url)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0Y8O4GMsJjIU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "105a085b-8ce3-412b-ea50-48b23f5fbd30"
      },
      "cell_type": "code",
      "source": [
        "print(train_path)\n",
        "print(test_path)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/.keras/datasets/train.tfrecord\n",
            "/content/.keras/datasets/test.tfrecord\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xBfXJf56KJs_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Building a Sentiment Analysis Model"
      ]
    },
    {
      "metadata": {
        "id": "yHlI8S9_PWjw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Vocabulary: list of each term we expect to see in data. We will turn our string-values into features vectors by using vocabulary. Each term in vocabulary is mapped to a cooridinate of feature vector. To convert string-value terms for an example into this vector format, we encode.\n",
        "\n",
        "Encoding happens this way...\n",
        "\n",
        "* Each coordinate gets a value of `0` if, vocabulary terms not found in the given example. Elsewhere `1` if found.\n",
        "* If examples terms not in vocabulary, then `throw away` those example terms."
      ]
    },
    {
      "metadata": {
        "id": "2vZxjAp7RcBy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Building the Input Pipeline"
      ]
    },
    {
      "metadata": {
        "id": "8B54UNk9JxY2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def _parse_function(record):\n",
        "  \"\"\"Extracts features and labels.\n",
        "  \n",
        "  Args:\n",
        "    record: File path to a TFRecord file    \n",
        "  Returns:\n",
        "    A `tuple` `(labels, features)`:\n",
        "      features: A dict of tensors representing the features\n",
        "      labels: A tensor with the corresponding labels.\n",
        "  \"\"\"\n",
        "  features = {\n",
        "      \"terms\": tf.VarLenFeature(dtype=tf.string), # terms are strings of varying lengths\n",
        "      \"labels\": tf.FixedLenFeature(shape=[1], dtype=tf.float32) # labels are 0 or 1\n",
        "  }\n",
        "  \n",
        "  parsed_features = tf.parse_single_example(record, features)\n",
        "  \n",
        "  terms = parsed_features['terms'].values\n",
        "  labels = parsed_features['labels']\n",
        "  \n",
        "  return {'terms': terms}, labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ifcimjQTTyT-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dc1e2e61-d9e6-4231-bb4e-41c84ed7f685"
      },
      "cell_type": "code",
      "source": [
        "# Create the Dataset object\n",
        "ds = tf.data.TFRecordDataset(train_path)\n",
        "# Map the features and labels with parse function\n",
        "ds = ds.map(_parse_function)\n",
        "ds"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<MapDataset shapes: ({terms: (?,)}, (1,)), types: ({terms: tf.string}, tf.float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "metadata": {
        "id": "idWOJac4UdVI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        },
        "outputId": "de36a215-80ff-4388-8f42-854820b9feba"
      },
      "cell_type": "code",
      "source": [
        "n = ds.make_one_shot_iterator().get_next() # retrieve the first example of training dataset.\n",
        "sess = tf.Session()\n",
        "sess.run(n)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'terms': array([b'but', b'it', b'does', b'have', b'some', b'good', b'action',\n",
              "         b'and', b'a', b'plot', b'that', b'is', b'somewhat', b'interesting',\n",
              "         b'.', b'nevsky', b'acts', b'like', b'a', b'body', b'builder',\n",
              "         b'and', b'he', b'isn', b\"'\", b't', b'all', b'that', b'attractive',\n",
              "         b',', b'in', b'fact', b',', b'imo', b',', b'he', b'is', b'ugly',\n",
              "         b'.', b'(', b'his', b'acting', b'skills', b'lack', b'everything',\n",
              "         b'!', b')', b'sascha', b'is', b'played', b'very', b'well', b'by',\n",
              "         b'joanna', b'pacula', b',', b'but', b'she', b'needed', b'more',\n",
              "         b'lines', b'than', b'she', b'was', b'given', b',', b'her',\n",
              "         b'character', b'needed', b'to', b'be', b'developed', b'.',\n",
              "         b'there', b'are', b'way', b'too', b'many', b'men', b'in', b'this',\n",
              "         b'story', b',', b'there', b'is', b'zero', b'romance', b',', b'too',\n",
              "         b'much', b'action', b',', b'and', b'way', b'too', b'dumb', b'of',\n",
              "         b'an', b'ending', b'.', b'it', b'is', b'very', b'violent', b'.',\n",
              "         b'i', b'did', b'however', b'love', b'the', b'scenery', b',',\n",
              "         b'this', b'movie', b'takes', b'you', b'all', b'over', b'the',\n",
              "         b'world', b',', b'and', b'that', b'is', b'a', b'bonus', b'.', b'i',\n",
              "         b'also', b'liked', b'how', b'it', b'had', b'some', b'stuff',\n",
              "         b'about', b'the', b'mafia', b'in', b'it', b',', b'not', b'too',\n",
              "         b'much', b'or', b'too', b'little', b',', b'but', b'enough',\n",
              "         b'that', b'it', b'got', b'my', b'attention', b'.', b'the',\n",
              "         b'actors', b'needed', b'to', b'be', b'more', b'handsome', b'.',\n",
              "         b'.', b'.', b'the', b'biggest', b'problem', b'i', b'had', b'was',\n",
              "         b'that', b'nevsky', b'was', b'just', b'too', b'normal', b',',\n",
              "         b'not', b'sexy', b'enough', b'.', b'i', b'think', b'for', b'most',\n",
              "         b'guys', b',', b'sascha', b'will', b'be', b'hot', b'enough', b',',\n",
              "         b'but', b'for', b'us', b'ladies', b'that', b'are', b'fans', b'of',\n",
              "         b'action', b',', b'nevsky', b'just', b'doesn', b\"'\", b't', b'cut',\n",
              "         b'it', b'.', b'overall', b',', b'this', b'movie', b'was', b'fine',\n",
              "         b',', b'i', b'didn', b\"'\", b't', b'love', b'it', b'nor', b'did',\n",
              "         b'i', b'hate', b'it', b',', b'just', b'found', b'it', b'to', b'be',\n",
              "         b'another', b'normal', b'action', b'flick', b'.'], dtype=object)},\n",
              " array([0.], dtype=float32))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "metadata": {
        "id": "LUNFXodNWFeL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Input Function"
      ]
    },
    {
      "metadata": {
        "id": "agqJDeiHV3da",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Create an input_fn that parses the tf.Examples from the given files,\n",
        "# and split them into features and targets\n",
        "def _input_fn(input_filenames, num_epochs=None, shuffle=True):\n",
        "  \n",
        "  # Create a dataset and map features and labels\n",
        "  ds = tf.data.TFRecordDataset(input_filenames)\n",
        "  ds = ds.map(_parse_function)\n",
        "  \n",
        "  if shuffle:\n",
        "    ds = ds.shuffle(10000)\n",
        "  \n",
        "  # Our feature data is variable-length, so we pad and batch\n",
        "  # each field of the dataset structure to whatever size is necessary.\n",
        "  ds = ds.padded_batch(25, ds.output_shapes)\n",
        "  \n",
        "  ds = ds.repeat(num_epochs)\n",
        "  \n",
        "  # Return the next batch of data.\n",
        "  features, labels = ds.make_one_shot_iterator().get_next()\n",
        "  return features, labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bJP2yHLdZMi2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Linear Model with Sparse Inputs and Explicit Vocabulary"
      ]
    },
    {
      "metadata": {
        "id": "eqgl8935XmHf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 50 informative terms that compose our model vocabulary \n",
        "informative_terms = (\"bad\", \"great\", \"best\", \"worst\", \"fun\", \"beautiful\",\n",
        "                     \"excellent\", \"poor\", \"boring\", \"awful\", \"terrible\",\n",
        "                     \"definitely\", \"perfect\", \"liked\", \"worse\", \"waste\",\n",
        "                     \"entertaining\", \"loved\", \"unfortunately\", \"amazing\",\n",
        "                     \"enjoyed\", \"favorite\", \"horrible\", \"brilliant\", \"highly\",\n",
        "                     \"simple\", \"annoying\", \"today\", \"hilarious\", \"enjoyable\",\n",
        "                     \"dull\", \"fantastic\", \"poorly\", \"fails\", \"disappointing\",\n",
        "                     \"disappointment\", \"not\", \"him\", \"her\", \"good\", \"time\",\n",
        "                     \"?\", \".\", \"!\", \"movie\", \"film\", \"action\", \"comedy\",\n",
        "                     \"drama\", \"family\")\n",
        "\n",
        "terms_feature_column = tf.feature_column.categorical_column_with_vocabulary_list(key=\"terms\", vocabulary_list=informative_terms)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FGewn5hTZtQu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "ed95f802-6313-4aa0-90b6-39fd143c5077"
      },
      "cell_type": "code",
      "source": [
        "my_optimizer = tf.train.AdagradOptimizer(learning_rate=0.1)\n",
        "my_optimizer = tf.contrib.estimator.clip_gradients_by_norm(my_optimizer, 5.0)\n",
        "\n",
        "feature_columns = [ terms_feature_column ]\n",
        "\n",
        "classifier = tf.estimator.LinearClassifier(\n",
        "    feature_columns = feature_columns,\n",
        "    optimizer = my_optimizer\n",
        ")\n",
        "\n",
        "classifier.train(\n",
        "    input_fn = lambda: _input_fn([train_path]),\n",
        "    steps = 1000\n",
        ")\n",
        "\n",
        "evaluation_metrics = classifier.evaluate(\n",
        "    input_fn = lambda: _input_fn([train_path]),\n",
        "    steps = 1000\n",
        ")\n",
        "print(\"Training set metrics: \")\n",
        "for m in evaluation_metrics:\n",
        "  print(m, evaluation_metrics[m])\n",
        "print(\"---\")\n",
        "\n",
        "evaluation_metrics = classifier.evaluate(\n",
        "    input_fn = lambda: _input_fn([test_path]),\n",
        "    steps = 1000\n",
        ")\n",
        "print(\"Testing set metrics: \")\n",
        "for m in evaluation_metrics:\n",
        "  print(m, evaluation_metrics[m])\n",
        "print(\"---\")"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training set metrics: \n",
            "accuracy 0.78824\n",
            "accuracy_baseline 0.5\n",
            "auc 0.87203777\n",
            "auc_precision_recall 0.8627088\n",
            "average_loss 0.45079547\n",
            "label/mean 0.5\n",
            "loss 11.269887\n",
            "prediction/mean 0.5136876\n",
            "global_step 1000\n",
            "---\n",
            "Testing set metrics: \n",
            "accuracy 0.78616\n",
            "accuracy_baseline 0.5\n",
            "auc 0.87018645\n",
            "auc_precision_recall 0.8601884\n",
            "average_loss 0.45149922\n",
            "label/mean 0.5\n",
            "loss 11.28748\n",
            "prediction/mean 0.51235497\n",
            "global_step 1000\n",
            "---\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mQjerLWDcm6p",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Deep Neural Network Model"
      ]
    },
    {
      "metadata": {
        "id": "jIk-Tr11joB_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "`tf.feature_column.indicator_column(categorical_column)` as input and represents multi-hot representation of given `categorical_column`"
      ]
    },
    {
      "metadata": {
        "id": "zUksCJMlcVaf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "72174e69-3d0c-40e3-e5b9-092f95f9e898"
      },
      "cell_type": "code",
      "source": [
        "classifier = tf.estimator.DNNClassifier(\n",
        "    feature_columns = [tf.feature_column.indicator_column(terms_feature_column)],\n",
        "    hidden_units = [20, 20],\n",
        "    optimizer = my_optimizer\n",
        ")\n",
        "\n",
        "try:\n",
        "  classifier.train(\n",
        "      input_fn = lambda: _input_fn([train_path]),\n",
        "      steps = 1000\n",
        "  )\n",
        "  \n",
        "  evaluation_metrics = classifier.evaluate(\n",
        "      input_fn = lambda: _input_fn([train_path]),\n",
        "      steps = 1000\n",
        "  )\n",
        "  print(\"Training set metrics: \")\n",
        "  for m in evaluation_metrics:\n",
        "    print(m, evaluation_metrics[m])\n",
        "  print(\"---\")\n",
        "  evaluation_metrics = classifier.evaluate(\n",
        "      input_fn = lambda: _input_fn([test_path]),\n",
        "      steps = 1\n",
        "  )\n",
        "  print(\"Testing set metrics: \")\n",
        "  for m in evaluation_metrics:\n",
        "    print(m, evaluation_metrics[m])\n",
        "  print(\"---\")\n",
        "except ValueError as err:\n",
        "  print(err)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training set metrics: \n",
            "accuracy 0.78804\n",
            "accuracy_baseline 0.5\n",
            "auc 0.8722286\n",
            "auc_precision_recall 0.86412716\n",
            "average_loss 0.44860134\n",
            "label/mean 0.5\n",
            "loss 11.215034\n",
            "prediction/mean 0.50501287\n",
            "global_step 1000\n",
            "---\n",
            "Testing set metrics: \n",
            "accuracy 0.68\n",
            "accuracy_baseline 0.52\n",
            "auc 0.7307692\n",
            "auc_precision_recall 0.71444154\n",
            "average_loss 0.6154636\n",
            "label/mean 0.52\n",
            "loss 15.38659\n",
            "prediction/mean 0.52615196\n",
            "global_step 1000\n",
            "---\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "AcNJz0OlioNj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Use an Embedding with Deep Neural Network Model"
      ]
    },
    {
      "metadata": {
        "id": "l4YEOgwni1Hl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "An `embedding_column` takes sparse data as input and returns a lower-dimensional dense vector as output."
      ]
    },
    {
      "metadata": {
        "id": "rSnesAtbesSe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "d4193999-1d2d-42ac-c5c8-c43ac9843778"
      },
      "cell_type": "code",
      "source": [
        "terms_embedding_column = tf.feature_column.embedding_column(terms_feature_column, dimension=2)\n",
        "feature_columns = [ terms_embedding_column ]\n",
        "\n",
        "my_optimizer = tf.train.AdagradOptimizer(learning_rate=0.1)\n",
        "my_optimizer = tf.contrib.estimator.clip_gradients_by_norm(my_optimizer, 5.0)\n",
        "classier = tf.estimator.DNNClassifier(\n",
        "    feature_columns = feature_columns,\n",
        "    hidden_units = [20, 20],\n",
        "    optimizer = my_optimizer\n",
        ")\n",
        "\n",
        "try:\n",
        "  classifier.train(\n",
        "      input_fn = lambda: _input_fn([train_path]),\n",
        "      steps = 1000\n",
        "  )\n",
        "  \n",
        "  evaluation_metrics = classifier.evaluate(\n",
        "      input_fn = lambda: _input_fn([train_path]),\n",
        "      steps = 1000\n",
        "  )\n",
        "  print(\"Training set metrics: \")\n",
        "  for m in evaluation_metrics:\n",
        "    print(m, evaluation_metrics[m])\n",
        "  print(\"---\")\n",
        "  \n",
        "  evaluation_metrics = classifier.evaluate(\n",
        "      input_fn = lambda: _input_fn([test_path]),\n",
        "      steps = 1000\n",
        "  )\n",
        "  print(\"Testing set metrics: \")\n",
        "  for m in evaluation_metrics:\n",
        "    print(m, evaluation_metrics[m])\n",
        "  print(\"---\")\n",
        "except ValueError as err:\n",
        "  print(err)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training set metrics: \n",
            "accuracy 0.788\n",
            "accuracy_baseline 0.5\n",
            "auc 0.87665486\n",
            "auc_precision_recall 0.86694\n",
            "average_loss 0.44380242\n",
            "label/mean 0.5\n",
            "loss 11.09506\n",
            "prediction/mean 0.53582823\n",
            "global_step 3000\n",
            "---\n",
            "Testing set metrics: \n",
            "accuracy 0.78408\n",
            "accuracy_baseline 0.5\n",
            "auc 0.8737385\n",
            "auc_precision_recall 0.86340797\n",
            "average_loss 0.4469021\n",
            "label/mean 0.5\n",
            "loss 11.172553\n",
            "prediction/mean 0.5349425\n",
            "global_step 3000\n",
            "---\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LKJAezTTpbJN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}